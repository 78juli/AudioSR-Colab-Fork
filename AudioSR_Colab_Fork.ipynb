{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/78juli/AudioSR-Colab-Fork/blob/main/AudioSR_Colab_Fork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYuiV2rlDizI"
      },
      "source": [
        "# AudioSR-Colab-Fork v0.5\n",
        "\n",
        "---\n",
        "Colab adaptation of AudioSR, with some tweaks:\n",
        "\n",
        "v0.5\n",
        "- input audio is resampled accordingly to 'input_cutoff' (instead of lowpass filtering)\n",
        "- each processed chunk is normalised at same LUFS level than input chunk (fix the volume drop issue)\n",
        "\n",
        "v0.4\n",
        "- code rework, inference.py created for local CLI usage.\n",
        "\n",
        "v0.3\n",
        "- added : multiband ensemble option to use original audio below the given cutoff frequency and the generated audio above.\n",
        "- fixed : other than .wav input error while saving the final audio\n",
        "\n",
        "v0.2\n",
        "- added a chunking feature to process input of any length\n",
        "- added stereo handling, stereo input channels will be splitted and processed independantly (dual mono) and then reconstructed as stereo audio.\n",
        "- added overlap feature to smooth the transitions between chunks (don't use high values because AudioSR is not 100% phase accurate and this will create weird phase cancellations accross the overlapping regions)\n",
        "---\n",
        "Adaptation & tweaks by [jarredou](https://https://github.com/jarredou/)\n",
        "\n",
        "Original work [AudioSR: Versatile Audio Super-resolution at Scale](https://github.com/haoheliu/versatile_audio_super_resolution) by Haohe Liu, Ke Chen, Qiao Tian, Wenwu Wang, Mark D. Plumbley\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7t23Tz5XIcON"
      },
      "outputs": [],
      "source": [
        "#@markdown # Installation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/haoheliu/versatile_audio_super_resolution.git\n",
        "%cd versatile_audio_super_resolution\n",
        "!pip install cog huggingface_hub unidecode phonemizer einops torchlibrosa transformers ftfy timm librosa pyloudnorm\n",
        "!pip install huggingface_hub transformers==4.30.2 gradio soundfile progressbar librosa audiosr unidecode\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jarredou/AudioSR-Colab-Fork/main/inference.py\n",
        "from IPython.display import clear_output\n",
        "clear_output(wait=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWUd27QECiLw"
      },
      "source": [
        "### **IMPORTANT NOTE**\n",
        "\n",
        "#### If the inference cell crashes, restart the runtime (do not disconnect, just restart it), else it will cause memory errors !\n",
        "\n",
        "*If you're are doing multiple runs, think also to restart the runtime every 4 or 5 files to clean up memory*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WfjZ_Q0OIepR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2020ffa4-ce77-494b-c162-76d3280ef839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/versatile_audio_super_resolution\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "Loading Model...\n",
            "Loading AudioSR: basic\n",
            "Loading model on cuda:0\n",
            "DiffusionWrapper has 258.20 M params.\n",
            "Model loaded!\n",
            "Setting seed to: 2923857089\n",
            "overlap = 0.08\n",
            "guidance_scale = 1.5\n",
            "ddim_steps = 40\n",
            "chunk_size = 5.12\n",
            "multiband_ensemble = True\n",
            "input file = the Sea.wav\n",
            "audio.shape = (1372790,)\n",
            "input cutoff = 11000\n",
            "Audio is mono\n",
            "enable_overlap = True\n",
            "Processing chunk 1 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:09<00:00,  4.25it/s]\n",
            "Processing chunk 2 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.10it/s]\n",
            "Processing chunk 3 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.09it/s]\n",
            "Processing chunk 4 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:06<00:00,  5.83it/s]\n",
            "Processing chunk 5 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.33it/s]\n",
            "Processing chunk 6 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.11it/s]\n",
            "Processing chunk 7 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.42it/s]\n",
            "Processing chunk 8 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.61it/s]\n",
            "Processing chunk 9 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.13it/s]\n",
            "Processing chunk 10 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.26it/s]\n",
            "Processing chunk 11 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:06<00:00,  5.77it/s]\n",
            "Processing chunk 12 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.22it/s]\n",
            "Processing chunk 13 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:08<00:00,  4.63it/s]\n",
            "Processing chunk 14 of 14 for Left/Mono channel\n",
            "Running DDIM Sampling with 40 timesteps\n",
            "DDIM Sampler: 100% 40/40 [00:07<00:00,  5.31it/s]\n",
            "file created: /content/drive/MyDrive/output_folder//SR_the Sea.wav\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%cd /content/versatile_audio_super_resolution\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.signal.windows import hann\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from cog import BasePredictor, Input, Path\n",
        "import tempfile\n",
        "import librosa\n",
        "from audiosr import build_model, super_resolution\n",
        "from scipy import signal\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "\n",
        "#@markdown #Inference\n",
        "input_file_path = '/content/drive/MyDrive/input/the Sea.wav' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/output_folder/' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "ddim_steps= 40 #@param {type:\"slider\", min:20, max:200, step:10}\n",
        "overlap = 0.08 #@param {type:\"slider\", min:0, max:0.96, step:0.04}\n",
        "guidance_scale=1.5 #@param {type:\"slider\", min:1, max:15, step:0.5}\n",
        "seed = 0 # @param {type:\"integer\"}\n",
        "chunk_size = 5.12 # @param [5.12, 10.24, 20.48] {type:\"raw\"}\n",
        "multiband_ensemble = False # @param {type:\"boolean\"}\n",
        "input_cutoff = \"11000\" #@param [20000, 19000, 18000, 17000, 16000, 14000, 13000, 12000, 11000, 10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000]\n",
        "input_cutoff = int(input_cutoff)\n",
        "\n",
        "\n",
        "\n",
        "!python inference.py --input \"{input_file_path}\" \\\n",
        "                     --output \"{output_folder}\" \\\n",
        "                     --ddim_steps {ddim_steps} \\\n",
        "                     --guidance_scale {guidance_scale} \\\n",
        "                     --seed {seed} \\\n",
        "                     --chunk_size {chunk_size} \\\n",
        "                     --overlap {overlap} \\\n",
        "                     --multiband_ensemble {multiband_ensemble} \\\n",
        "                     --input_cutoff {input_cutoff}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}